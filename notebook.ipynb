{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Race, Dialect, and Gender**\n",
    "\n",
    "Dialects are considered variations of languages that are generally mutually understandable. Due to English  being spoken in multiple different countries among diverse groups of speakers, English speakers exhibit diverse accents, localized words, and grammatical structures based on their countries and regions. Major English dialects are often classified into British Isles, North American, and Australasian categories. Dialects are not only linked to geographical regions but also to specific social groups. Each English-speaking country has its version of Standard English, often associated with education and formal communication.\n",
    "\n",
    "In this study, I examined and analyized how Microsoft's Speech-to-text translation API performs on different dialects, specifically standard American English, standard British English, and African American Venacular English, to see if the API's algorithm performs better on any of these groups compared to the others. I also wanted to see if this, or differences in race or differences in gender would yield a more drastic performance gap.\n",
    "\n",
    "For the dataset, I collected the transcripts of SNL monologues from Youtube performed by different men and women, all of which were native English speakers. I downloaded the videos from Youtube from the website https://y2down.cc/en/youtube-wav.html. After getting the .wav files, I collected the transcripts from https://snltranscripts.jt.org/2022/megan-thee-stallion-monologue.phtml, then edited the transcript by listening to the files and making changes whereever needed. I also edited the .wav files, so it would only include the speaker's speech throughout the script, and edited out parts that had a lot of background noise (for example, clapping) to make ensure that the speech-to-text transcription algorithm is as fair between different speakers as possible.\n",
    "\n",
    "I had three different ways of analyzing performance as mentioned before. First and foremost, I analyized the performance between dialects of English with speakers being categorized into one of three groups containing the following people:\n",
    "\n",
    "1. African American Venacular English:\n",
    "   - Keke Palmer (Black)\n",
    "   - Tiffany Haddish (Black)\n",
    "   - Eddie Murphy (Black)\n",
    "   - Megan Thee Stallion (Black)\n",
    "\n",
    "2. Standard American English\n",
    "   - Billie Eilish (white)\n",
    "   - Kim Kardashian (white)\n",
    "   - Don Cheadle (Black)\n",
    "   - Ayo Edebiri (Black)\n",
    "   - Jack Harlow (white)\n",
    "   - Pete Davidson (white)\n",
    "\n",
    "3. Standard British English\n",
    "   - Daniel Kaluuya (Black)\n",
    "   - Idris Elba (Black)\n",
    "   - Benedict Cumberbatch (white)\n",
    "   - Phoebe Waller-Bridge (white)\n",
    "\n",
    "\n",
    "The second analysis measured how race affects the accuracy of speech-to-text translation, with two categories in this case:\n",
    "1. Black Speakers:\n",
    "   - Daniel Kaluuya \n",
    "   - Idris Elba \n",
    "   - Don Cheatle \n",
    "   - Keke Palmer \n",
    "   - Tiffany Haddish \n",
    "   - Eddie Murphy \n",
    "   - Megan Thee Stallion \n",
    "   - Ayo Edebiri \n",
    "  \n",
    "2. White Speakers:\n",
    "   - Benedict Cumberbatch \n",
    "   - Jack Harlow\n",
    "   - Pete Davidson\n",
    "   - Phoebe Waller-Bridge \n",
    "   - Billie Eilish \n",
    "   - Kim Kardashian \n",
    "\n",
    "Third, I also wanted to see if gender would have a noticable impact on the performance of the speech-to-text algorithm, with categorizing the speakers into one of two categories:\n",
    "1. Women\n",
    "   - Keke Palmer \n",
    "   - Tiffany Haddish \n",
    "   - Megan Thee Stallion\n",
    "   - Ayo Edebiri\n",
    "   - Billie Eilish \n",
    "   - Kim Kardashian  \n",
    "   - Phoebe Waller-Bridge\n",
    "2. Men\n",
    "   - Benedict Cumberbatch\n",
    "   - Pete Davidson\n",
    "   - Jack Harlow\n",
    "   - Eddie Murphy \n",
    "   - Daniel Kaluuya \n",
    "   - Idris Elba\n",
    "\n",
    "My hypotheses was that dialect will have the biggest impact, second will be gender, then out of these three race will result in the smallest difference between groups. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to run the algorithm you will need to install serval dependencies and set up a virtual environent. Follow these steps to ensure smooth running of the algorithm:\n",
    "\n",
    "1. Open your terminal and type `dotnet add package Microsoft.CognitiveServices.Speech`\n",
    "   \n",
    "2. Now, still in the terminal type `code Program.cs` to ensure that the system is set up correctly. \n",
    "\n",
    "3. To be able to run C# code from a Jupyter Python kernel, ensure that you have .NET installed\n",
    "   To download do the following steps:\n",
    "   1. Go to https://dotnet.microsoft.com/en-us/download\n",
    "   2. Download the appropriate package for your computer \n",
    "   3. To find the path of where .NET was installed open your terminal and do the following:\n",
    "      - type \"dotnet\" into your terminal to ensure that it downloaded correctly\n",
    "         it should output something like this:\n",
    "\n",
    "         `(base) yourname@dhcp-vl2041-25861 ~ % dotnet`\n",
    "\n",
    "         `Usage: dotnet [options]`\n",
    "\n",
    "         `Usage: dotnet [path-to-application]`\n",
    "\n",
    "         `Options:`\n",
    "\n",
    "         ` -h|--help         Display help.`\n",
    "\n",
    "         ` --info            Display .NET information.`\n",
    "\n",
    "         ` --list-sdks       Display the installed SDKs.`\n",
    "\n",
    "         ` --list-runtimes   Display the installed runtimes.`\n",
    "\n",
    "         `path-to-application:`\n",
    "\n",
    "         `The path to an application .dll file to execute.`\n",
    "\n",
    "      - If it's successful, type \"where dotnet\" into your terminal\n",
    "         That should output something like this:\n",
    "\n",
    "         \n",
    "         `(base) yourname@dhcp-vl2041-25861 ~ % where dotnet`\n",
    "\n",
    "        ` /usr/local/share/dotnet/dotnet`\n",
    "\n",
    "         Copy the line \"`/usr/local/share/dotnet/dotnet`\". This may be slightly different for you and that okay. In the code cell below (3 cells below) replace the line `dotnet_path = \"/usr/local/share/dotnet/dotnet\"` with your actual path\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PS: Running the following cell takes about 20-30 minutes depending on your computer. I prepopulated the files in case you (my TA or whoever is grading this:D) don't want to wait that long. If you want to double check that that this cell still runs as expected you can comment out the for loop and instead run the part currently commented out. You can also replace the name with any name from the following list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ayo_edebiri', 'benedict_cumberbatch', 'billie_eilish', 'daniel_kaluuya', 'don_cheadle', 'eddie_murphy', 'idris_elba', 'jack_harlow', 'keke_palmer', 'kim_kardashian', 'megan_thee_stallion', 'pete_davidson', 'phoebe_waller_bridge', 'tiffany_haddish']\n"
     ]
    }
   ],
   "source": [
    "from helpers import name_info\n",
    "\n",
    "print(list(name_info.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textdistance in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (4.6.1)\n"
     ]
    }
   ],
   "source": [
    "! pip install textdistance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import helpers \n",
    "speaker_list = list(helpers.name_info.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speech recognition started for ayo_edebiri.\n",
      "Speech recognition stopped for ayo_edebiri.\n",
      "Speech recognition started for benedict_cumberbatch.\n",
      "Speech recognition stopped for benedict_cumberbatch.\n",
      "Speech recognition started for billie_eilish.\n",
      "Speech recognition stopped for billie_eilish.\n",
      "Speech recognition started for daniel_kaluuya.\n",
      "Speech recognition stopped for daniel_kaluuya.\n",
      "Speech recognition started for don_cheadle.\n",
      "Speech recognition stopped for don_cheadle.\n",
      "Speech recognition started for eddie_murphy.\n",
      "Speech recognition stopped for eddie_murphy.\n",
      "Speech recognition started for idris_elba.\n",
      "Speech recognition stopped for idris_elba.\n",
      "Speech recognition started for jack_harlow.\n",
      "Speech recognition stopped for jack_harlow.\n",
      "Speech recognition started for keke_palmer.\n",
      "Speech recognition stopped for keke_palmer.\n",
      "Speech recognition started for kim_kardashian.\n",
      "Speech recognition stopped for kim_kardashian.\n",
      "Speech recognition started for megan_thee_stallion.\n",
      "Speech recognition stopped for megan_thee_stallion.\n",
      "Speech recognition started for pete_davidson.\n",
      "Speech recognition stopped for pete_davidson.\n",
      "Speech recognition started for phoebe_waller_bridge.\n",
      "Speech recognition stopped for phoebe_waller_bridge.\n",
      "Speech recognition started for tiffany_haddish.\n",
      "Speech recognition stopped for tiffany_haddish.\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import textdistance\n",
    "\n",
    "def run_speech_to_text(name):\n",
    "    current_directory = os.getcwd()\n",
    "    dotnet_path = \"/usr/local/share/dotnet/dotnet\"  # Replace with your actual path\n",
    "    subprocess.run([dotnet_path, \"run\", name], cwd=current_directory)\n",
    "\n",
    "# Example usage\n",
    "speaker_list = list(name_info.keys())\n",
    "\n",
    "for speaker in speaker_list:\n",
    "  run_speech_to_text(speaker)\n",
    "\n",
    "# This part can be un-commented if you don't want to wait the 30 minutes to rerun and instead just want to check one or a few people's transcripts. \n",
    "# run_speech_to_text(\"INSERT_YOUR_SPEAKER\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To analyze how Microsoft's API performed, I wanted to measure the accuracy based on several factors. \n",
    "I did some minor pre-processing, like turning the text documents into strings, taking out punctuation, and turning all characters into lowercase letters to reduce translation mistakes that are lower than word level (for example, putting a different punctionation mark, or capitalizing letters differently).\n",
    "\n",
    "I used some predefined functions in Python's \"textdistance\" library (taken from https://pypi.org/project/textdistance/), as well as some code I wrote. To get an overall view on how the API performed on different demographics, I used 4 types measurements to calculate how it performed on each of them. \n",
    "\n",
    "These 4 types were:\n",
    "1. Edit based:\n",
    "   This measures how much post-translation editing a person would have to do get to the accurate transcript. The functions for this type were\n",
    "   - Accuracy: how many words the API got correctly --> closer to 1 is better, 0 is worse\n",
    "   - Word-error-rate: how much insertions/deletion/swaps to get to the correct transcript --> closer to 0 is better, 1 is worse\n",
    "2. Token based\n",
    "   - Cosine-similarity: calculates the similarity of two vectors by the dot product and divides it by the magnitudes of each vector (1 is better)\n",
    "   - Jaccard_distance: calculates the similarity of two text documents by comparing the number unique of terms used in both documents (1 is better)\n",
    "3. Compression based\n",
    "   Тhis is based on the idea that similar strings can be compressed more effectively than less similar ones ones.\n",
    "   - Square root: compares the size of compressed data (which is thesum of square roots of counts of every element) between the 2 texts (0 is better) \n",
    "4. Phonetic based\n",
    "   - Match Rating Approach (MRA): \"indexing of words by their pronunciation developed by Western Airlines in 1977 for the indexation and comparison of homophonous names\" (Moore, G B.; Kuhns, J L.; Treffzs, J L.; Montgomery, C A. (Feb 1, 1977))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install textdistance\n",
    "import textdistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import string\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "def generate_scores(name):\n",
    "\n",
    "    with open(\"transcript_files/\" + name + \".txt\") as f:\n",
    "        reference = f.readlines()\n",
    "    with open(\"output_files/\" + name + \"_output.txt\") as f:\n",
    "        hypothesis = f.readlines()\n",
    "\n",
    "    reference_str = \"\"\n",
    "    for lines in reference:\n",
    "        reference_str += lines\n",
    "\n",
    "    hypothesis_str = \"\"\n",
    "    for lines in hypothesis:\n",
    "        hypothesis_str += lines\n",
    "\n",
    "    hypothesis = re.sub(r'[^\\w\\s]',\" \",hypothesis_str.lower())\n",
    "    reference = re.sub(r'[^\\w\\s]',\" \",reference_str.lower())\n",
    "    \n",
    "    # edit based\n",
    "    accuracy = get_accuracy(reference, hypothesis)\n",
    "    wer = get_wer(reference, hypothesis)\n",
    "    # token based \n",
    "    cos_sim = cosine_sim(reference, hypothesis)\n",
    "    jaccard_distance = textdistance.jaccard(reference, hypothesis)\n",
    "    # compression based\n",
    "    sqrt_dist = textdistance.sqrt_ncd(reference, hypothesis)\n",
    "    # phonetic based\n",
    "    mra_distance = textdistance.mra(reference, hypothesis)\n",
    "\n",
    "    return (accuracy, wer, cos_sim, jaccard_distance, sqrt_dist, mra_distance)\n",
    "\n",
    "\n",
    "def get_wer(reference, hypothesis):\n",
    "    ref_words = reference.split()\n",
    "    hyp_words = hypothesis.split()\n",
    "    d = np.zeros((len(ref_words) + 1, len(hyp_words) + 1))\n",
    "    for i in range(len(ref_words) + 1):\n",
    "        d[i, 0] = i\n",
    "    for j in range(len(hyp_words) + 1):\n",
    "        d[0, j] = j\n",
    "    for i in range(1, len(ref_words) + 1):\n",
    "        for j in range(1, len(hyp_words) + 1):\n",
    "            if ref_words[i - 1] == hyp_words[j - 1]:\n",
    "                d[i, j] = d[i - 1, j - 1]\n",
    "            else:\n",
    "                substitution = d[i - 1, j - 1] + 1\n",
    "                insertion = d[i, j - 1] + 1\n",
    "                deletion = d[i - 1, j] + 1\n",
    "                d[i, j] = min(substitution, insertion, deletion)\n",
    "\n",
    "    wer = d[len(ref_words), len(hyp_words)] / len(ref_words)\n",
    "    return wer\n",
    "\n",
    "\n",
    "def normalize(text):\n",
    "    re.sub(r'[^\\w\\s]',\" \",text.lower())\n",
    "    text = text.split(\" \")\n",
    "    return text\n",
    "\n",
    "def cosine_sim(text1, text2):\n",
    "    vectorizer = TfidfVectorizer(tokenizer=normalize)\n",
    "    tfidf = vectorizer.fit_transform([text1, text2])\n",
    "    return ((tfidf * tfidf.T).A)[0, 1]\n",
    "\n",
    "\n",
    "def get_accuracy(reference, hypothesis):\n",
    "    ref_words = reference.split()\n",
    "    hyp_words = hypothesis.split()\n",
    "    d = np.zeros((len(ref_words) + 1, len(hyp_words) + 1))\n",
    "    for i in range(len(ref_words) + 1):\n",
    "        d[i, 0] = i\n",
    "    for j in range(len(hyp_words) + 1):\n",
    "        d[0, j] = j\n",
    "    for i in range(1, len(ref_words) + 1):\n",
    "        for j in range(1, len(hyp_words) + 1):\n",
    "            if ref_words[i - 1] == hyp_words[j - 1]:\n",
    "                d[i, j] = d[i - 1, j - 1]\n",
    "            else:\n",
    "                d[i, j] = d[i - 1, j - 1] + 1\n",
    "\n",
    "    accuracy = d[len(ref_words), len(hyp_words)] / len(ref_words)\n",
    "    return accuracy\n",
    "\n",
    "# Display the result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from helpers import name_info\n",
    "# from analysis import generate_scores \n",
    "\n",
    "speaker_scores = {}\n",
    "for name in name_info.keys():\n",
    "  speaker_scores[name] = generate_scores(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Women: (0.971, 0.128, 0.975, 0.935, 0.422, 2.286)\n",
      "Men: (0.89, 0.108, 0.979, 0.961, 0.423, 1.714)\n",
      "\n",
      "SAE Speakers: (0.859, 0.077, 0.985, 0.959, 0.42, 1.8)\n",
      "SBE Speakers:: (0.959, 0.13, 0.974, 0.959, 0.422, 1.833)\n",
      "AAVE Speakers:: (0.992, 0.162, 0.969, 0.908, 0.429, 2.667)\n",
      "\n",
      "Black Speakers:: (0.986, 0.152, 0.969, 0.938, 0.424, 2.0)\n",
      "White Speakers:: (0.875, 0.084, 0.985, 0.958, 0.421, 2.0)\n"
     ]
    }
   ],
   "source": [
    "# sae_speakers, sbe_speakers, aave_speakers,female_speakers, male_speakers, black_speakers, white_speakers\n",
    "from helpers import name_info\n",
    "\n",
    "def extract_info_of_criteria(criteria, group):\n",
    "  #accuracy, wer, cos_sim, jaccard_distance, ratcliff_ob, sqrt_didt, mra_distance)\n",
    "  acc, wer, cos_sim, jacc_dist, sqrt_dist, mra_distance = 0, 0, 0, 0, 0, 0\n",
    "  num_in_group = 0\n",
    "\n",
    "  for speaker in speaker_scores:\n",
    "    if name_info[speaker][group] == criteria:\n",
    "      acc += speaker_scores[speaker][0]\n",
    "      wer += speaker_scores[speaker][1]\n",
    "      cos_sim += speaker_scores[speaker][2]\n",
    "      jacc_dist += speaker_scores[speaker][3]\n",
    "      sqrt_dist+=  speaker_scores[speaker][4]\n",
    "      mra_distance +=  speaker_scores[speaker][5]\n",
    "      num_in_group += 1\n",
    "    \n",
    "  return (round(acc/num_in_group, 3), \n",
    "          round(wer/num_in_group, 3), \n",
    "          round(cos_sim/num_in_group, 3),  \n",
    "          round(jacc_dist/num_in_group, 3),  \n",
    "          round(sqrt_dist/num_in_group, 3), \n",
    "          round(mra_distance/num_in_group, 3))\n",
    "\n",
    "score_of_men = extract_info_of_criteria(\"male\", \"gender\")\n",
    "score_of_women = extract_info_of_criteria(\"female\", \"gender\")\n",
    "\n",
    "score_of_sae = extract_info_of_criteria(\"sae\", \"dialect\")\n",
    "score_of_sbe = extract_info_of_criteria(\"sbe\", \"dialect\")\n",
    "score_of_aave = extract_info_of_criteria(\"aave\", \"dialect\")\n",
    "\n",
    "score_of_black_speakers = extract_info_of_criteria(\"black\", \"race\")\n",
    "score_of_white_speakers = extract_info_of_criteria(\"white\", \"race\")\n",
    "\n",
    "\n",
    "print(\"Women: \" + str(score_of_women))\n",
    "print(\"Men: \" + str(score_of_men))\n",
    "print()\n",
    "\n",
    "print(\"SAE Speakers: \" + str(score_of_sae))\n",
    "print(\"SBE Speakers:: \" + str(score_of_sbe))\n",
    "print(\"AAVE Speakers:: \" + str(score_of_aave))\n",
    "print()\n",
    "\n",
    "\n",
    "print(\"Black Speakers:: \" + str(score_of_black_speakers))\n",
    "print(\"White Speakers:: \" + str(score_of_white_speakers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since some of the measurements indicate high similarity when the score is 0, and some of them 1, I decided to flip the scores of the measurements that indicate high similarity when the score is 0 for the numbers to be easier to interpret. For the MRA, I decided to get the sum of all MRA scores for all demographics, then give the score of (1 - x/sum) for each demographic where x is their MRA score in order to normalize them. Therefore, the higher the modified MRA score the better the algorithm performed for that demographic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Women:\n",
      "[0.971, 0.872, 0.975, 0.935, 0.578, 0.84]\n",
      "\n",
      "Men:\n",
      "[0.89, 0.892, 0.979, 0.961, 0.577, 0.88]\n",
      "\n",
      "Standard American English Speakers:\n",
      "[0.859, 0.923, 0.985, 0.959, 0.58, 0.874]\n",
      "\n",
      "Standard British English Speakers:\n",
      "[0.959, 0.87, 0.974, 0.959, 0.578, 0.872]\n",
      "\n",
      "African American Vernacular English Speakers:\n",
      "[0.992, 0.838, 0.969, 0.908, 0.571, 0.813]\n",
      "\n",
      "Black Speakers:\n",
      "[0.986, 0.848, 0.969, 0.938, 0.576, 0.86]\n",
      "\n",
      "White Speakers:\n",
      "[0.875, 0.916, 0.985, 0.958, 0.579, 0.86]\n",
      "\n",
      "[[0.971, 0.872, 0.975, 0.935, 0.578, 0.84], [0.89, 0.892, 0.979, 0.961, 0.577, 0.88], [0.859, 0.923, 0.985, 0.959, 0.58, 0.874], [0.959, 0.87, 0.974, 0.959, 0.578, 0.872], [0.992, 0.838, 0.969, 0.908, 0.571, 0.813], [0.986, 0.848, 0.969, 0.938, 0.576, 0.86], [0.875, 0.916, 0.985, 0.958, 0.579, 0.86]]\n"
     ]
    }
   ],
   "source": [
    "# Closer to 0 is a better score: wer [1], square root distance [4]\n",
    "# Closer to 1 is a better score: accuracy [0], cosine similarity [2], jaccard distance [3]\n",
    "# The smaller the score the better: mra distance [5]\n",
    "reverse_index = {0: \"Women\", 1: \"Men\", 2: \"Standard American English Speakers\", 3:\"Standard British English Speakers\", 4:\"African American Vernacular English Speakers\", 5:\"Black Speakers\",  6:\"White Speakers\"}\n",
    "# We want to flip index 1 and index 4\n",
    "list_of_measurements = [score_of_women, score_of_men, score_of_sae, score_of_sbe, score_of_aave, score_of_black_speakers, score_of_white_speakers]\n",
    "list_of_measurements_modified = []\n",
    "\n",
    "mra_sum = sum(tup[5] for tup in list_of_measurements)\n",
    "\n",
    "for measurment in list_of_measurements:\n",
    "  measurment_mod = list(measurment)\n",
    "  measurment_mod[1] = (1 - measurment[1])\n",
    "  measurment_mod[4] = round((1 - measurment[4]), 3) \n",
    "  measurment_mod[5] = round((1 - (measurment[5]/mra_sum)), 3) \n",
    "  list_of_measurements_modified.append((measurment_mod))\n",
    "\n",
    "index = 0\n",
    "for line in list_of_measurements_modified:\n",
    "  print(reverse_index[index] + \":\")\n",
    "  print(str(line))\n",
    "  print()\n",
    "  index += 1\n",
    "print(list_of_measurements_modified)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Measurement 1 Rankings:\n",
      "Standard American English Speakers: 1\n",
      "Women: 2\n",
      "Standard British English Speakers: 3\n",
      "Men: 4\n",
      "Black Speakers: 5\n",
      "African American Vernacular English Speakers: 6\n",
      "\n",
      "Measurement 2 Rankings:\n",
      "Standard American English Speakers: 1\n",
      "Standard British English Speakers: 2\n",
      "Men: 3\n",
      "Women: 4\n",
      "Black Speakers: 5\n",
      "African American Vernacular English Speakers: 6\n",
      "\n",
      "Measurement 3 Rankings:\n",
      "Standard American English Speakers: 1\n",
      "Standard British English Speakers: 2\n",
      "Men: 3\n",
      "Black Speakers: 4\n",
      "Women: 5\n",
      "African American Vernacular English Speakers: 6\n",
      "\n",
      "Measurement 4 Rankings:\n",
      "Standard American English Speakers: 1\n",
      "Standard British English Speakers: 2\n",
      "Women: 3\n",
      "Black Speakers: 4\n",
      "Men: 5\n",
      "African American Vernacular English Speakers: 6\n",
      "\n",
      "Measurement 5 Rankings:\n",
      "Women: 1\n",
      "Standard American English Speakers: 2\n",
      "Standard British English Speakers: 3\n",
      "Men: 4\n",
      "Black Speakers: 5\n",
      "African American Vernacular English Speakers: 6\n",
      "\n",
      "Measurement 6 Rankings:\n",
      "Women: 1\n",
      "Standard American English Speakers: 2\n",
      "Standard British English Speakers: 3\n",
      "Black Speakers: 4\n",
      "Men: 5\n",
      "African American Vernacular English Speakers: 6\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Demographics labels\n",
    "demographics_labels = [\n",
    "    \"Women\", \"Men\", \"Standard American English Speakers\",\n",
    "    \"Standard British English Speakers\", \"African American Vernacular English Speakers\",\n",
    "    \"Black Speakers\", \"White Speakers\"\n",
    "]\n",
    "\n",
    "measurement =  [\"Accuracy\", \"Word-Error-Rate\", \"Cosine Similarity\", \"Jaccard Distance\", \"Square Root Distance\", \"Match Rating Approach\"]\n",
    "\n",
    "\n",
    "rankings = {}\n",
    "\n",
    "# Loop through each measurement\n",
    "for i in range(6):\n",
    "    # Get the scores for each demographic\n",
    "    scores = list_of_measurements_modified[:][i]\n",
    "    \n",
    "    # Get the indices that would sort the array\n",
    "    sorted_indices = np.argsort(scores)[::-1]  # Reverse the indices for descending order\n",
    "    \n",
    "    # Create a ranking dictionary for the measurement\n",
    "    ranking_dict = {demographics_labels[j]: rank + 1 for rank, j in enumerate(sorted_indices)}\n",
    "    \n",
    "    # Add the ranking dictionary to the overall rankings dictionary\n",
    "    rankings[measurement[i]] = ranking_dict\n",
    "\n",
    "# Print the rankings\n",
    "for measurement, ranking_dict in rankings.items():\n",
    "    print(f'\\n{measurement} Rankings:')\n",
    "    for demographic, rank in ranking_dict.items():\n",
    "        print(f' {rank}: {demographic}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "acc, wer, cos_sim, jacc_dist, sqrt_dist, mra_distance = 0, 0, 0, 0, 0, 0\n",
    "\n",
    "| Ranking | Accuracy | Word-Error-Rate | Cosine Similarity | Jaccard Distance | Square Root Difference | Match Rating Approach  \n",
    "|:--------:|:--------:|:--------:|:--------:|:--------:|:--------:|:--------:|\n",
    "|   1   |   Black Speakers  |  Row 1   |  Row 1   | Row 1   | Row 1   | Row 1   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of conciseness, and to have a singular number to rank all categories' overall performance, I then took the average score of all measurement types for each demographic, since all the results are now normalized and higher scores indicate better performance. It's important to note, however, that not all measurments carry the same weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83360.71s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.26.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Standard British English Speakers 0.8687\n",
      "2. Standard American English Speakers 0.8633\n",
      "3. Men 0.8632\n",
      "4. Black Speakers 0.8628\n",
      "5. White Speakers 0.8622\n",
      "6. Women 0.8618\n",
      "7. African American Vernacular English Speakers 0.8485\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "avg_scoring = {}\n",
    "idx = 0\n",
    "for demographic in list_of_measurements_modified:\n",
    "  demo = reverse_index[idx]\n",
    "  avg_scoring[demo] = round(np.mean(demographic), 4)\n",
    "  idx += 1\n",
    "\n",
    "sorted_scoring = dict(sorted(avg_scoring.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "place = 1\n",
    "for key, val in sorted_scoring.items():\n",
    "  print(str(place) + \". \" + key + \" \" + str(val))\n",
    "  place += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dialects:\n",
      "Microsoft's API performed best on Standard American English of all categories, performing -0.005 points better than Standard British English.\n",
      "More concerningly, it performed 0.015 better compared to African-American Vernacular English, which was also the worst performing demographic of all groups.\n",
      "\n",
      "Gender:\n",
      "Microsoft's API performed better on women speakers compared to men, scoring -0.001 points better.\n",
      "\n",
      "Race:\n",
      "Microsoft's API performed better on white speakers compared to Black speakers, scoring -0.001 points better.\n"
     ]
    }
   ],
   "source": [
    "diff_sae_and_sbe = round(sorted_scoring[\"Standard American English Speakers\"] - sorted_scoring[\"Standard British English Speakers\"], 3)\n",
    "diff_sae_and_aave = round(sorted_scoring[\"Standard American English Speakers\"] - sorted_scoring[\"African American Vernacular English Speakers\"], 3)\n",
    "\n",
    "diff_gender = round(sorted_scoring[\"Women\"] - sorted_scoring[\"Men\"], 3)\n",
    "\n",
    "diff_race = round(sorted_scoring[\"White Speakers\"] - sorted_scoring[\"Black Speakers\"], 3)\n",
    "\n",
    "print(\"Dialects:\")\n",
    "print(\"Microsoft's API performed best on Standard American English of all categories, performing \" + str(diff_sae_and_sbe) + \" points better than Standard British English.\")\n",
    "print(\"More concerningly, it performed \" + str(diff_sae_and_aave) + \" better compared to African-American Vernacular English, which was also the worst performing demographic of all groups.\")\n",
    "print()\n",
    "\n",
    "print(\"Gender:\")\n",
    "print(\"Microsoft's API performed better on women speakers compared to men, scoring \" + str(diff_gender) + \" points better.\")\n",
    "print()\n",
    "\n",
    "print(\"Race:\")\n",
    "print(\"Microsoft's API performed better on white speakers compared to Black speakers, scoring \" + str(diff_race) + \" points better.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these results, we can see that my original hypotheses was not entirely correct. I predicted that dialect will make the biggest JONES JONES FINISH THIS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
